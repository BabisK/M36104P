import numpy

def softmax(w, x):

    pass

def gradient_descent(X, T, step, iterations):
    trows, tcolumns = T.shape
    xrows, xcolumns = X.shape
    W = numpy.zeros((trows, tcolumns))

    pass

def main():
    pass

if __name__ == '__main__':
    main()
